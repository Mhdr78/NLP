{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"translation_en_fa.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a9d1df3ee446465e84fc2bce173881f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd8b6a556e124fe39a00168b59d81796","IPY_MODEL_b90e89b427ef440c96aeb0b2c09eb81e","IPY_MODEL_d16a338be6044a49b13750a16c774392"],"layout":"IPY_MODEL_1ec706dbf1d342e78d1278a1f2bf1f8e"}},"dd8b6a556e124fe39a00168b59d81796":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c86717ef40254830baf9a5d89bc5c3e7","placeholder":"​","style":"IPY_MODEL_e7456707965146998f91086db203428e","value":"100%"}},"b90e89b427ef440c96aeb0b2c09eb81e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a468ab808994cb8b8362ec022959cdc","max":496,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b00f1c09f5c4faa9181689452ec75a9","value":496}},"d16a338be6044a49b13750a16c774392":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0ad094695c43c28518cbfbd6e15349","placeholder":"​","style":"IPY_MODEL_477935f2e184449dacb315101046d678","value":" 496/496 [01:42&lt;00:00,  5.80ba/s]"}},"1ec706dbf1d342e78d1278a1f2bf1f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c86717ef40254830baf9a5d89bc5c3e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7456707965146998f91086db203428e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a468ab808994cb8b8362ec022959cdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b00f1c09f5c4faa9181689452ec75a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e0ad094695c43c28518cbfbd6e15349":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"477935f2e184449dacb315101046d678":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40971786abe244d391f61a7faa9d2a9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18be97c523bd4246860cb645060e832d","IPY_MODEL_6393180f96a84654ae553151b61601be","IPY_MODEL_38f52ba51f974bfc94464b4835ff5771"],"layout":"IPY_MODEL_e1777f220f74489a8d0ef8d6d510ccd7"}},"18be97c523bd4246860cb645060e832d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ed12e0bf1b14eb38e2906e0a11df3ac","placeholder":"​","style":"IPY_MODEL_f8e82d5cf3ee43c1bc8d86f3c3919d5e","value":"100%"}},"6393180f96a84654ae553151b61601be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16540e67aea84e0e8a0cf46452c78b7e","max":62,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edbe86df600f484b8dac1b06efa620e7","value":62}},"38f52ba51f974bfc94464b4835ff5771":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1785f92d95c24f7b9a7d3a3c2acce6a8","placeholder":"​","style":"IPY_MODEL_4963ae322cca467c8b64913bcdedebf9","value":" 62/62 [00:11&lt;00:00,  5.25ba/s]"}},"e1777f220f74489a8d0ef8d6d510ccd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ed12e0bf1b14eb38e2906e0a11df3ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e82d5cf3ee43c1bc8d86f3c3919d5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16540e67aea84e0e8a0cf46452c78b7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edbe86df600f484b8dac1b06efa620e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1785f92d95c24f7b9a7d3a3c2acce6a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4963ae322cca467c8b64913bcdedebf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32f4c80c45d647b78848dcb70c8d46f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c81846a40247452bad5d69f5ec62276b","IPY_MODEL_3c2c7508089c48f8b89c30bc51681b52","IPY_MODEL_c495231df6ae47bc931c2a3e603a0dd4"],"layout":"IPY_MODEL_d666a33db0fd48cea98554448c9d234b"}},"c81846a40247452bad5d69f5ec62276b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12f78d03abca47849058543c5e689cab","placeholder":"​","style":"IPY_MODEL_09823c2465214e559f26f20648d9ac7b","value":"100%"}},"3c2c7508089c48f8b89c30bc51681b52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3ce664f2d914322a24d3cde86248e62","max":56,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18dac38d870c41b790f255591f20f8f7","value":56}},"c495231df6ae47bc931c2a3e603a0dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_825970f18a424a2289f29fbdcc3d4e54","placeholder":"​","style":"IPY_MODEL_058965a236814d4bb4524c687aa247e7","value":" 56/56 [00:10&lt;00:00,  5.43ba/s]"}},"d666a33db0fd48cea98554448c9d234b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12f78d03abca47849058543c5e689cab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09823c2465214e559f26f20648d9ac7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3ce664f2d914322a24d3cde86248e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18dac38d870c41b790f255591f20f8f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"825970f18a424a2289f29fbdcc3d4e54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058965a236814d4bb4524c687aa247e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1MwBr0AeZkLysDGPHn35kl-ATmfMV_WSp&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7OUIdVPVfVm6","outputId":"6c0b1bf4-56b4-48f4-be50-0d93b0f44164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1MwBr0AeZkLysDGPHn35kl-ATmfMV_WSp\n","To: /content/TEP.en-fa.en\n","\r  0% 0.00/21.1M [00:00<?, ?B/s]\r 99% 21.0M/21.1M [00:00<00:00, 208MB/s]\r100% 21.1M/21.1M [00:00<00:00, 208MB/s]\n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1yL3ZS-UpgtNeJtgVIInBSl907PkzoaxO&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIG1KlXdgU0B","outputId":"b832d9d1-e88a-4471-ff1f-8db1ec06a88a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1yL3ZS-UpgtNeJtgVIInBSl907PkzoaxO\n","To: /content/TEP.en-fa.fa\n","\r  0% 0.00/34.0M [00:00<?, ?B/s]\r 26% 8.91M/34.0M [00:00<00:00, 78.0MB/s]\r100% 34.0M/34.0M [00:00<00:00, 198MB/s] \n"]}]},{"cell_type":"code","source":["! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uajGipsNh9YK","outputId":"7388e3ad-b582-4012-b495-e3fe758d5fbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n","\u001b[K     |████████████████████████████████| 362 kB 13.1 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 24.7 MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[K     |████████████████████████████████| 92 kB 11.9 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 61.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 50.0 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 10.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 19.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 15.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 44.4 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.10)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 60.9 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 75.3 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (3.17.3)\n","Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, huggingface-hub, fsspec, aiohttp, xxhash, transformers, sentencepiece, responses, portalocker, colorama, sacrebleu, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 colorama-0.4.5 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 portalocker-2.5.1 pyyaml-6.0 responses-0.18.0 sacrebleu-2.1.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install hazm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OE8KXWf3rXG3","outputId":"47dedfad-817a-4f92-c48f-ae7daae7ba8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hazm\n","  Using cached hazm-0.7.0-py3-none-any.whl (316 kB)\n","Collecting libwapiti>=0.2.1\n","  Using cached libwapiti-0.2.1.tar.gz (233 kB)\n","Collecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 14.6 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=2233230cc247ff0a73eacf2a1724d4bde19a56014f8356006b0308dc5ca453e5\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=155188 sha256=b37e738958e4bddd24ce89eb73c0c6d0c007b0b992f6a2df502ea4af7830c4c0\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"]}]},{"cell_type":"code","source":["import hazm\n","# importing panda library\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","normalizer = hazm.Normalizer()"],"metadata":{"id":"qddjidYSrdTa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file1 = open('data/TEP.en-fa.en', 'r')\n","file2 = open('data/TEP.en-fa.fa', 'r')\n","text_file = open(\"data/comma_separated-en-fa.txt\", \"w\")\n","\n","txt_data = 'translation\\n'\n","text_file.write(txt_data)\n","dic_list = []\n","counter = 0\n","\n","# Using for loop\n","print(\"Using for loop\")\n","for line1 in file1:\n","    line2 = file2.readline()\n","    line2 = normalizer.normalize(line2)\n","    dic_list.append({'en': line1.replace('\\n', ''), 'fa': line2.replace('\\n', '')})\n","    # text_file.write(txt_data)\n","    # counter += 1\n","    # if counter % 1000 == 0:\n","    #     # print(counter)\n","\n","#print(txt_data)\n","  \n","# Closing files\n","file1.close()\n","file2.close()\n","# text_file.close()\n","\n","dic = {'translation': dic_list}\n","df = pd.DataFrame(dic) \n","    \n","# saving the dataframe \n","df.to_csv('en-fa.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0yxRGOnez0R","outputId":"9311593a-87c6-4515-8e36-91a071eafb4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using for loop\n"]}]},{"cell_type":"code","source":["tmp = open('data/comma_separated-en-fa.txt', 'r')\n","count = 0\n","for line in tmp:\n","  count += 1\n","  if count <10:\n","    print(line, end='')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tkmCnRRgn8a","outputId":"60fc17ba-5a00-4ab9-8a33-7f3e66e1aed7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["translation\n","{'en': 'raspy breathing .', 'fa': 'صدای خر خر. '}\n","{'en': 'dad .', 'fa': 'پدر. '}\n","{'en': 'maybe its the wind .', 'fa': 'شاید صدای باد باشه. '}\n","{'en': 'no .', 'fa': 'نه. '}\n","{'en': 'stop please stop .', 'fa': 'دست نگه دارید خواهش میکنم دست نگه دارید. '}\n","{'en': 'you have a week  evans then well burn the house .', 'fa': 'اوانز تو فقط یک هفته وقت داری وگرنه خونتو خواهیم سوزوند. '}\n","{'en': 'william .', 'fa': 'ویلیام. '}\n","{'en': 'god damn it  william .', 'fa': 'لعنتی. ویلیام ۸. '}\n"]}]},{"cell_type":"code","source":["# readinag given csv file\n","# and creating dataframe\n","dataframe1 = pd.read_csv(\"data/comma_separated-en-fa.txt\")\n","  \n","# storing this dataframe in a csv file\n","dataframe1.to_csv('data/en-fa.csv', index = None)"],"metadata":{"id":"jyiLyfrBqDD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['translation'][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"qMTz8TDv4qnh","outputId":"260c92c4-07b9-49a6-d17f-7f564afae0fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'پدر. '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["print(hazm.word_tokenize(normalizer.normalize('پدر .')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ja9m0h4o8B5r","outputId":"3e428c3d-2477-4741-e865-5d93e5d78b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['پدر', '.']\n"]}]},{"cell_type":"markdown","source":["##Split data into train, valid, test"],"metadata":{"id":"FdIjqbXZyL-1"}},{"cell_type":"code","source":[""],"metadata":{"id":"iwqv2q2bqXUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, valid = train_test_split(df, test_size=0.1, random_state=1)\n","train, test = train_test_split(train, test_size=0.1, random_state=1)\n","\n","\n","train = train.reset_index(drop=True)\n","valid = valid.reset_index(drop=True)\n","test = test.reset_index(drop=True)"],"metadata":{"id":"RKAuUwKzvCAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.to_csv('data/train_en_fa.csv', index=None)\n","valid.to_csv('data/valid_en_fa.csv', index=None)\n","test.to_csv('data/test_en_fa.csv', index=None)"],"metadata":{"id":"VxsAaTSJvyxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['translation'][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-t1cCdYn-8IV","outputId":"6d6f6b18-8495-438b-ed45-0bdfdb6aa581"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'en': 'not to prolong an agony fatal .',\n"," 'fa': 'برای عذاب دادن به انسانهای در حال مرگ نه. '}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["##Save csv files on Drive"],"metadata":{"id":"pxNqJAJNyCuv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ca_DvX-1woZz","outputId":"e400fc16-7632-40dd-f1af-f936c97bb755"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/NLP/en-fa/train_en_fa.csv', 'w') as f:\n","  f.write('data/train_en_fa.csv')"],"metadata":{"id":"att_Q7vPwqat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/NLP/en-fa/valid_en_fa.csv', 'w') as f:\n","  f.write('data/valid_en_fa.csv')"],"metadata":{"id":"55Jc_jnzxTbe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/NLP/en-fa/test_en_fa.csv', 'w') as f:\n","  f.write('data/test_en_fa.csv')"],"metadata":{"id":"x-GCLy1RxwuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDGdMh4Fxzyh","outputId":"fa3a4a0e-b049-415b-fb17-75d2ccc2c909"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All changes made in this colab session should now be visible in Drive.\n"]}]},{"cell_type":"code","source":["train_file = pd.read_csv('data/train_en_fa.csv')\n","train_file"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"hoDlKSevMb1d","outputId":"c0cafb52-dfac-4467-f219-c38c5350b207"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ParserError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-167-81f4d2425259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_en_fa.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 7, saw 5\n"]}]},{"cell_type":"markdown","source":["##Load dataset with load_dataset()"],"metadata":{"id":"5AuGiQYbyjG8"}},{"cell_type":"code","source":["from datasets.dataset_dict import DatasetDict\n","from datasets import load_dataset, load_metric, Dataset\n","# dataset = load_dataset('csv', data_files={'train': 'data/train_en_fa.csv', 'validation': 'data/valid_en_fa.csv', 'test': 'data/test_en_fa.csv'})\n","train_dataset = Dataset.from_pandas(train)\n","valid_dataset = Dataset.from_pandas(valid)\n","test_dataset = Dataset.from_pandas(test)\n","\n","dataset = DatasetDict()\n","\n","dataset['train'] = train_dataset\n","dataset['validation'] = valid_dataset\n","dataset['test'] = test_dataset\n","\n","metric = load_metric(\"sacrebleu\")"],"metadata":{"id":"kN8w9fW5yA7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMK2I6gYSH2Q","outputId":"f4164904-7319-4a2c-8985-f2bd849abab1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['translation'],\n","        num_rows: 495789\n","    })\n","    validation: Dataset({\n","        features: ['translation'],\n","        num_rows: 61209\n","    })\n","    test: Dataset({\n","        features: ['translation'],\n","        num_rows: 55088\n","    })\n","})"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"PypJ2YihziR4","outputId":"85d89613-d2c4-43a7-dcfe-75e2b68f19bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              translation\n","0       {'en': 'so , dish . i just wanna make sure my ...\n","1       {'en': 'not to prolong an agony fatal .', 'fa'...\n","2       {'en': 'i love you , mathilda .', 'fa': 'دوست ...\n","3              {'en': 'blow up .', 'fa': 'عصبانی کردن. '}\n","4                {'en': 'curious .', 'fa': 'کم پیدایی. '}\n","...                                                   ...\n","495784  {'en': 'and be nice to her .', 'fa': 'اون یک ف...\n","495785  {'en': 'his killers a dead man .', 'fa': 'قاتل...\n","495786  {'en': 'why are you home so early?', 'fa': 'ام...\n","495787  {'en': 'a young jew named jesus had come along...\n","495788  {'en': 'they aren't slaves of soo?', 'fa': 'او...\n","\n","[495789 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-7abe98a9-7028-42b0-a733-78b3c1257fe5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'en': 'so , dish . i just wanna make sure my ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'en': 'not to prolong an agony fatal .', 'fa'...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'en': 'i love you , mathilda .', 'fa': 'دوست ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'en': 'blow up .', 'fa': 'عصبانی کردن. '}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'en': 'curious .', 'fa': 'کم پیدایی. '}</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495784</th>\n","      <td>{'en': 'and be nice to her .', 'fa': 'اون یک ف...</td>\n","    </tr>\n","    <tr>\n","      <th>495785</th>\n","      <td>{'en': 'his killers a dead man .', 'fa': 'قاتل...</td>\n","    </tr>\n","    <tr>\n","      <th>495786</th>\n","      <td>{'en': 'why are you home so early?', 'fa': 'ام...</td>\n","    </tr>\n","    <tr>\n","      <th>495787</th>\n","      <td>{'en': 'a young jew named jesus had come along...</td>\n","    </tr>\n","    <tr>\n","      <th>495788</th>\n","      <td>{'en': 'they aren't slaves of soo?', 'fa': 'او...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>495789 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7abe98a9-7028-42b0-a733-78b3c1257fe5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7abe98a9-7028-42b0-a733-78b3c1257fe5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7abe98a9-7028-42b0-a733-78b3c1257fe5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["dataset['train'][0]['translation']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLrBaYuu3fsf","outputId":"bd2eccff-759b-4e23-84d4-5ceeb5320ae7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'en': 'so , dish . i just wanna make sure my .',\n"," 'fa': 'پس میخام مطمئن بشم که. '}"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["import datasets\n","import random\n","from IPython.display import display, HTML\n","def show_random_elements(dataset, num_examples=5):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, datasets.ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","    display(HTML(df.to_html()))\n","show_random_elements(dataset[\"train\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zxdEW2PF3kB3","outputId":"6bde1d66-58d7-4934-e5cd-1608f36f2704"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'en': 'going through .', 'fa': 'میریم بین اون. '}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'en': 'how nice , youre all dressed up to the nines .', 'fa': '، چه خوب شما همتون به خودتون میرسین. '}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'en': 'perhaps listen , you greasy cuckold .', 'fa': 'شاید گوش کن بیچاره گمراه. '}</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'en': 'is that enough?', 'fa': 'کافیه؟ '}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'en': 'excuse me , ignacio .', 'fa': 'پوزش می‌خوام، ایگناسیو. '}</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["fake_preds = [\"hello there\", \"سلام فرمانده\"]\n","fake_labels = [[\"hello there\"], [\"سلام فرمانده\"]]\n","metric.compute(predictions=fake_preds, references=fake_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiXNGXELXwY4","outputId":"8dab8068-e90e-4f76-8dd2-71f47aa4ca14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bp': 1.0,\n"," 'counts': [4, 2, 0, 0],\n"," 'precisions': [100.0, 100.0, 0.0, 0.0],\n"," 'ref_len': 4,\n"," 'score': 0.0,\n"," 'sys_len': 4,\n"," 'totals': [4, 2, 0, 0]}"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n","\n","model_size = \"small\"\n","model_name = f\"persiannlp/mt5-{model_size}-parsinlu-translation_en_fa\"\n","tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","\n","\n","def run_model(input_string, **generator_args):\n","    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n","    res = model.generate(input_ids, **generator_args)\n","    output = tokenizer.batch_decode(res, skip_special_tokens=True)\n","    print(output)\n","    return output\n","\n","\n","# run_model(\"Praise be to Allah, the Cherisher and Sustainer of the worlds;\")\n","# run_model(\"shrouds herself in white and walks penitentially disguised as brotherly love through factories and parliaments; offers help, but desires power;\")\n","# run_model(\"He thanked all fellow bloggers and organizations that showed support.\")\n","# run_model(\"Races are held between April and December at the Veliefendi Hippodrome near Bakerky, 15 km (9 miles) west of Istanbul.\")\n","# run_model(\"I want to pursue PhD in Computer Science about social network,what is the open problem in social networks?\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkY4Sw9hYyla","outputId":"d086fe6f-371f-462b-adf3-1b1e1eaa850d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/1223857dcb252328187a151e6b041f717a67a42af84294b94b718d70f312c51a.da687df25d297aebfd515b6699506f3229d24423c0da1a02f45396bfa8197a95\n","loading file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/e3f05d8475329196f91efe328bca4d874911511e75770ed3c54d66e4c926b9cd.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","loading file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d722a97ea564ba3e502c4cfa7fe8c1eb95af8cdd20a7996747a18a7b18c779d2.0558f7cc3ad625be48810ea2eb04e6ceffb95f729c3e4de4b6df10985fcfd59f\n","loading configuration file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8d32536a0cdbcfdea702cc63f1767eca514da510c473e9e133a73a543484a0c0.21003b32ab0f4df14527fb8bc7aef4769f8c29e6460c1e07f05f4f2962605a8f\n","Model config MT5Config {\n","  \"_name_or_path\": \"persiannlp/mt5-small-parsinlu-translation_en_fa\",\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","loading configuration file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8d32536a0cdbcfdea702cc63f1767eca514da510c473e9e133a73a543484a0c0.21003b32ab0f4df14527fb8bc7aef4769f8c29e6460c1e07f05f4f2962605a8f\n","Model config MT5Config {\n","  \"architectures\": [\n","    \"MT5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 1024,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 8,\n","  \"num_heads\": 6,\n","  \"num_layers\": 8,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","loading weights file https://huggingface.co/persiannlp/mt5-small-parsinlu-translation_en_fa/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/213ee185a13e7d44a0b48fb478fe6fb059973a6b328be7936243ad34c7b622ac.daec9b491a96495cb28c12355d9cd4ca4ebaff3041113394ef3f4e0d752e7f84\n","All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n","\n","All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at persiannlp/mt5-small-parsinlu-translation_en_fa.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"iNDawJO_fXHa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06b36e2f-dfeb-4c4b-d23f-da319e3100a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jul 14 00:10:24 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    30W /  70W |  15086MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["%reset -f"],"metadata":{"id":"lqpAwEf1aVLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLEQk-2hYMfz","outputId":"ed1681f8-7f3c-419a-85aa-3080c8243750"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[30273, 261, 714, 1371, 259, 98923, 309, 1], [1494, 339, 259, 7845, 259, 98923, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["with tokenizer.as_target_tokenizer():\n","    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mLgb08adt8l","outputId":"8331231a-05f5-4455-99e1-28d0c674742c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[30273, 261, 714, 1371, 259, 98923, 309, 1], [1494, 339, 259, 7845, 259, 98923, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}]},{"cell_type":"code","source":["prefix = \"\"\n","max_input_length = 128\n","max_target_length = 128\n","source_lang = \"en\"\n","target_lang = \"fa\"\n","def preprocess_function(examples):\n","    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"8ESUkiJyd7Gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_function(dataset['train'][:2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BLk3Zkqd9vr","outputId":"6ee49c74-45d7-4725-b8ee-435fc8368022"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[510, 259, 261, 90564, 259, 260, 259, 266, 1627, 259, 82711, 2149, 7779, 1037, 259, 260, 1], [776, 288, 65143, 461, 2780, 680, 83478, 259, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[6423, 822, 41950, 8764, 633, 26081, 21470, 633, 934, 260, 1], [259, 1699, 259, 112382, 4283, 259, 53522, 554, 11632, 2791, 509, 4299, 548, 43017, 3237, 260, 1]]}"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["tokenized_datasets = dataset.map(preprocess_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["a9d1df3ee446465e84fc2bce173881f4","dd8b6a556e124fe39a00168b59d81796","b90e89b427ef440c96aeb0b2c09eb81e","d16a338be6044a49b13750a16c774392","1ec706dbf1d342e78d1278a1f2bf1f8e","c86717ef40254830baf9a5d89bc5c3e7","e7456707965146998f91086db203428e","3a468ab808994cb8b8362ec022959cdc","3b00f1c09f5c4faa9181689452ec75a9","0e0ad094695c43c28518cbfbd6e15349","477935f2e184449dacb315101046d678","40971786abe244d391f61a7faa9d2a9f","18be97c523bd4246860cb645060e832d","6393180f96a84654ae553151b61601be","38f52ba51f974bfc94464b4835ff5771","e1777f220f74489a8d0ef8d6d510ccd7","7ed12e0bf1b14eb38e2906e0a11df3ac","f8e82d5cf3ee43c1bc8d86f3c3919d5e","16540e67aea84e0e8a0cf46452c78b7e","edbe86df600f484b8dac1b06efa620e7","1785f92d95c24f7b9a7d3a3c2acce6a8","4963ae322cca467c8b64913bcdedebf9","32f4c80c45d647b78848dcb70c8d46f5","c81846a40247452bad5d69f5ec62276b","3c2c7508089c48f8b89c30bc51681b52","c495231df6ae47bc931c2a3e603a0dd4","d666a33db0fd48cea98554448c9d234b","12f78d03abca47849058543c5e689cab","09823c2465214e559f26f20648d9ac7b","f3ce664f2d914322a24d3cde86248e62","18dac38d870c41b790f255591f20f8f7","825970f18a424a2289f29fbdcc3d4e54","058965a236814d4bb4524c687aa247e7"]},"id":"reFaS22AeQ6i","outputId":"f1da10b3-2413-4f12-817c-ca908d09cbd3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/496 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d1df3ee446465e84fc2bce173881f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/62 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40971786abe244d391f61a7faa9d2a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/56 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f4c80c45d647b78848dcb70c8d46f5"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"],"metadata":{"id":"BPvrjf5ei4GT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","args = Seq2SeqTrainingArguments(\n","    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=1,\n","    predict_with_generate=True    \n",")"],"metadata":{"id":"sg1otQiJeU-y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"204c4538-f534-4671-acdd-020d3a95888e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"vjqIGDHvjGg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","    return preds, labels\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"],"metadata":{"id":"f7rZ_pYCjJe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"sJtleaM0jOrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%reset -f"],"metadata":{"id":"Loj937k2CTIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#trainer.train(resume_from_checkpoint = True)\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GL3ZG9btjSWJ","outputId":"ed2e2cfd-ec26-480e-be71-a03e56e6c0bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 495789\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 30987\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15731' max='30987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15731/30987 1:27:05 < 1:24:28, 3.01 it/s, Epoch 0.51/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15000\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15000/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15500\n","Configuration saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15500/config.json\n","Model weights saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-14000] due to args.save_total_limit\n"]}]},{"cell_type":"code","source":["trainer.save_model('model/')"],"metadata":{"id":"CXceiW4ML9UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import MarianMTModel, MarianTokenizer\n","src_text = ['My name is Sarah and I live in London']\n","model_name = 'persiannlp/mt5-small-parsinlu-translation_en_fa-finetuned-en-to-fa/checkpoint-30000'\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"],"metadata":{"id":"7mVQqsePkkVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","for dirname, _, filenames in os.walk('opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"metadata":{"id":"ViAHIAZHknav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1MwBr0AeZkLysDGPHn35kl-ATmfMV_WSp&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9de022a9-b418-4d96-fb21-fb4cfab6e9af","id":"_tmyeuedv7Y2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1MwBr0AeZkLysDGPHn35kl-ATmfMV_WSp\n","To: /content/TEP.en-fa.en\n","100% 21.1M/21.1M [00:00<00:00, 105MB/s] \n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1yL3ZS-UpgtNeJtgVIInBSl907PkzoaxO&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c11d7ee-4f06-41ef-aae1-433eb6fb8456","id":"OL2NqmJ4v7Y3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1yL3ZS-UpgtNeJtgVIInBSl907PkzoaxO\n","To: /content/TEP.en-fa.fa\n","100% 34.0M/34.0M [00:00<00:00, 134MB/s] \n"]}]},{"cell_type":"code","source":["! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"347a4459-3e92-4151-bd24-a4163f9270aa","executionInfo":{"status":"ok","timestamp":1658388900710,"user_tz":-270,"elapsed":24438,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"-oStQ8lsv7Y3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n","\u001b[K     |████████████████████████████████| 362 kB 8.7 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 53.2 MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[K     |████████████████████████████████| 92 kB 12.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 63.5 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 77.9 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.7 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 79.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 76.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 77.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.10)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 73.4 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 47.8 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (3.17.3)\n","Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, huggingface-hub, fsspec, aiohttp, xxhash, transformers, sentencepiece, responses, portalocker, colorama, sacrebleu, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 colorama-0.4.5 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 portalocker-2.5.1 pyyaml-6.0 responses-0.18.0 sacrebleu-2.1.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install hazm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"df5ef617-4dc1-45a6-e4ba-e92ae8d73c17","executionInfo":{"status":"ok","timestamp":1658388912006,"user_tz":-270,"elapsed":11303,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"HbOCrxqfv7Y3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hazm\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 8.2 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 62.2 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 69.7 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=8487894594c62913f9b86ff39c7266c4e16836aaeca1e62415f3ec6a7a019372\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=153948 sha256=0af3514f24dc386ac70b5f80219b9589fdaf3f3042ebc99302d9c3bbc7854d47\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"]}]},{"cell_type":"code","source":["import hazm\n","# importing panda library\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import json\n","\n","\n","normalizer = hazm.Normalizer()"],"metadata":{"id":"dJ3ovX4Sv7Y3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file1 = open('data/TEP.en-fa.en', 'r')\n","file2 = open('data/TEP.en-fa.fa', 'r')\n","text_file = open(\"data/comma_separated-en-fa.txt\", \"w\")\n","\n","txt_data = 'translation\\n'\n","text_file.write(txt_data)\n","dic_list = []\n","counter = 0\n","\n","# Using for loop\n","print(\"Using for loop\")\n","for line1 in file1:\n","    line2 = file2.readline()\n","    line2 = normalizer.normalize(line2)\n","    dic_list.append({'en': line1.replace('\\n', ''), 'fa': line2.replace('\\n', '')})\n","    # text_file.write(txt_data)\n","    # counter += 1\n","    # if counter % 1000 == 0:\n","    #     # print(counter)\n","\n","#print(txt_data)\n","  \n","# Closing files\n","file1.close()\n","file2.close()\n","# text_file.close()\n","\n","dic = {'translation': dic_list}\n","df = pd.DataFrame(dic) \n","    \n","# saving the dataframe \n","df.to_csv('en-fa.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"b5d31340-8f3a-4c83-9a9c-51713f530c12","executionInfo":{"status":"error","timestamp":1657838826334,"user_tz":-270,"elapsed":5,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"Tl1VCVckv7Y4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-73a0d6771bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/TEP.en-fa.en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfile2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/TEP.en-fa.fa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/comma_separated-en-fa.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtxt_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'translation\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/TEP.en-fa.en'"]}]},{"cell_type":"code","source":["print(hazm.word_tokenize(normalizer.normalize('پدر .')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e428c3d-2477-4741-e865-5d93e5d78b29","id":"LAXUKL64v7Y4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['پدر', '.']\n"]}]},{"cell_type":"code","source":["data = {'translation': []}\n","counter = 0\n","for row in df['translation']:\n","  # counter += 1\n","  data['translation'].append({'en': row['en'], 'fa': row['fa']})\n","  # if counter % 5:\n","  #   print(type(row))\n","\n","with open('data/dataset_en_fa.json', 'w') as f:\n","  json.dump(data, f, indent=4)"],"metadata":{"id":"QpxPbbiSaXCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_json('data/dataset_en_fa.json')"],"metadata":{"id":"NVYgTbMDbFJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Split data into train, valid, test"],"metadata":{"id":"AwWWelhcv7Y5"}},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f62618f-d4e6-4708-d063-a4ee7ca9a2f5","id":"xyLQ5Ez2v7Y5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["612086"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["train, valid = train_test_split(df, test_size=0.1, random_state=1)\n","train, test = train_test_split(train, test_size=0.1, random_state=1)\n","\n","\n","train = train.reset_index(drop=True)\n","valid = valid.reset_index(drop=True)\n","test = test.reset_index(drop=True)"],"metadata":{"id":"SPQZoY9xv7Y5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('data/train_en_fa.json', 'w') as f:\n","  json.dump(train, f, indent=4)\n","\n","with open('data/valid_en_fa.json', 'w') as f:\n","  json.dump(valid, f, indent=4)\n","\n","with open('data/test_en_fa.json', 'w') as f:\n","  json.dump(test, f, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"outputId":"16fd3676-e555-42ec-93be-f9b6f1b8e5a1","id":"obEmr2V7v7Y5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-26e9d77c9fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_en_fa.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/valid_en_fa.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Object of type DataFrame is not JSON serializable"]}]},{"cell_type":"code","source":["import json\n","data = {'translation': []}\n","for row in train['translation']:\n","  data['translation'].append({'en': row['en'], 'fa': row['fa']})\n","\n","with open('data/train_en_fa.json', 'w') as f:\n","  json.dump(data, f, indent=4)\n","\n","data = {'translation': []}\n","for row in valid['translation']:\n","  data['translation'].append({'en': row['en'], 'fa': row['fa']})\n","\n","with open('data/valid_en_fa.json', 'w') as f:\n","  json.dump(data, f, indent=4)\n","\n","\n","data = {'translation': []}\n","for row in test['translation']:\n","  data['translation'].append({'en': row['en'], 'fa': row['fa']})\n","\n","with open('data/test_en_fa.json', 'w') as f:\n","  json.dump(data, f, indent=4)"],"metadata":{"id":"qRuoz7rVv7Y5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Save csv files on Drive"],"metadata":{"id":"LYIpIqUUv7Y6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1412568-ad64-49ca-b6e7-e1089ba998dc","id":"IT3V9Esmv7Y6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import shutil"],"metadata":{"id":"UK4NGaesOSP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shutil.copy(\"data/train_en_fa.json\",\"/content/drive/MyDrive/NLP/en-fa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"dabce107-68e5-481d-b2f7-6461b252cf7e","id":"YqKDUhrRv7Y6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/NLP/en-fa/train_en_fa.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["shutil.copy(\"data/valid_en_fa.json\",\"/content/drive/MyDrive/NLP/en-fa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"5df5b4c2-f679-4765-df77-ac2d73c6b187","id":"hqUU4ExDv7Y6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/NLP/en-fa/valid_en_fa.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["shutil.copy(\"data/test_en_fa.json\",\"/content/drive/MyDrive/NLP/en-fa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"d6199e4e-5e7a-4c7b-a948-79de8658cc27","id":"1i1By000v7Y6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/NLP/en-fa/test_en_fa.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"256d4d5d-a131-4820-e37a-bc73bc686ecd","id":"y9QNaWNsv7Y6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All changes made in this colab session should now be visible in Drive.\n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1-1wUqZY04IWJ5H8L5sbr858_qsXREkP3&export=download\n","!gdown https://drive.google.com/u/0/uc?id=1-64KK34aipJn50n4vGBJ3qzMPywn-xmn&export=download\n","!gdown https://drive.google.com/u/0/uc?id=1-2T9xIdLLC71_9aTu2HGuZdgb7ueO0KL&export=download\n","\n","!mkdir data\n","\n","!mv \"train_en_fa.json\" \"data/train_en_fa.json\"\n","!mv \"valid_en_fa.json\" \"data/valid_en_fa.json\"\n","!mv \"test_en_fa.json\" \"data/test_en_fa.json\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfmCOwg9iwOc","outputId":"2812aa5a-b9df-4d49-c49a-fc469cac9ed9","executionInfo":{"status":"ok","timestamp":1658389067254,"user_tz":-270,"elapsed":8311,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/u/0/uc?id=1-1wUqZY04IWJ5H8L5sbr858_qsXREkP3\n","To: /content/train_en_fa.json\n","100% 123M/123M [00:01<00:00, 107MB/s] \n","Downloading...\n","From: https://drive.google.com/u/0/uc?id=1-64KK34aipJn50n4vGBJ3qzMPywn-xmn\n","To: /content/valid_en_fa.json\n","100% 15.1M/15.1M [00:00<00:00, 107MB/s] \n","Downloading...\n","From: https://drive.google.com/u/0/uc?id=1-2T9xIdLLC71_9aTu2HGuZdgb7ueO0KL\n","To: /content/test_en_fa.json\n","100% 13.6M/13.6M [00:00<00:00, 75.9MB/s]\n"]}]},{"cell_type":"markdown","source":["##Load dataset with load_dataset()"],"metadata":{"id":"A1MBpIpNv7Y7"}},{"cell_type":"code","source":["train = pd.read_json('data/train_en_fa.json')\n","valid = pd.read_json('data/valid_en_fa.json')\n","test = pd.read_json('data/test_en_fa.json')"],"metadata":{"id":"Bb4Zg1K2lt_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets.dataset_dict import DatasetDict\n","from datasets import load_dataset, load_metric, Dataset\n","# dataset = load_dataset('json', data_files={'train': 'data/train_en_fa.json', 'validation': 'data/valid_en_fa.json', 'test': 'data/test_en_fa.json'}, field='')\n","\n","train_dataset = Dataset.from_pandas(train)\n","valid_dataset = Dataset.from_pandas(valid)\n","test_dataset = Dataset.from_pandas(test)\n","\n","dataset = DatasetDict()\n","\n","dataset['train'] = train_dataset\n","dataset['validation'] = valid_dataset\n","dataset['test'] = test_dataset\n","\n","metric = load_metric(\"sacrebleu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["94d3b0174b2548bf88889747675a1543","d72d6042aca44de88fc0891ce0062540","571788fe045445728bc19e713e6c4ef9","bb5331a0b7ab4fd486ac1fad70ecd499","672826eda35e4170b3e13b0318011452","821c9b5869b14fe19a86ed23bbd5cee9","440c61b6581c4b8baa78ce405ce08db9","d81f3f2fd80e4c549998859361ef2034","1a96e1b5a4a9406db61cfcc5a86020e5","71f5f7caf7754ad98e3c902ece5a322e","49359a8e18c5440db8297c05b20d7582"]},"executionInfo":{"status":"ok","timestamp":1658389076156,"user_tz":-270,"elapsed":2884,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"outputId":"636f7133-f748-4373-f35c-af05ff288c19","id":"HeXzLwbGv7Y7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d3b0174b2548bf88889747675a1543"}},"metadata":{}}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3f0907b-75bb-4ff4-99ec-2165d9441368","executionInfo":{"status":"ok","timestamp":1658389076157,"user_tz":-270,"elapsed":12,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"h5JGQvdTv7Y7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['translation'],\n","        num_rows: 495789\n","    })\n","    validation: Dataset({\n","        features: ['translation'],\n","        num_rows: 61209\n","    })\n","    test: Dataset({\n","        features: ['translation'],\n","        num_rows: 55088\n","    })\n","})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"4c9f8218-dc95-41cd-9551-f03ac91a371b","executionInfo":{"status":"ok","timestamp":1658389076158,"user_tz":-270,"elapsed":11,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"H_DngWKpv7Y7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              translation\n","0       {'en': 'so , dish . i just wanna make sure my ...\n","1       {'en': 'not to prolong an agony fatal .', 'fa'...\n","2       {'en': 'i love you , mathilda .', 'fa': 'دوست ...\n","3              {'en': 'blow up .', 'fa': 'عصبانی کردن. '}\n","4                {'en': 'curious .', 'fa': 'کم پیدایی. '}\n","...                                                   ...\n","495784  {'en': 'and be nice to her .', 'fa': 'اون یک ف...\n","495785  {'en': 'his killers a dead man .', 'fa': 'قاتل...\n","495786  {'en': 'why are you home so early?', 'fa': 'ام...\n","495787  {'en': 'a young jew named jesus had come along...\n","495788  {'en': 'they aren't slaves of soo?', 'fa': 'او...\n","\n","[495789 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-b3ac04d3-315e-4a4e-b3ac-5594381589ed\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'en': 'so , dish . i just wanna make sure my ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'en': 'not to prolong an agony fatal .', 'fa'...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'en': 'i love you , mathilda .', 'fa': 'دوست ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'en': 'blow up .', 'fa': 'عصبانی کردن. '}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'en': 'curious .', 'fa': 'کم پیدایی. '}</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495784</th>\n","      <td>{'en': 'and be nice to her .', 'fa': 'اون یک ف...</td>\n","    </tr>\n","    <tr>\n","      <th>495785</th>\n","      <td>{'en': 'his killers a dead man .', 'fa': 'قاتل...</td>\n","    </tr>\n","    <tr>\n","      <th>495786</th>\n","      <td>{'en': 'why are you home so early?', 'fa': 'ام...</td>\n","    </tr>\n","    <tr>\n","      <th>495787</th>\n","      <td>{'en': 'a young jew named jesus had come along...</td>\n","    </tr>\n","    <tr>\n","      <th>495788</th>\n","      <td>{'en': 'they aren't slaves of soo?', 'fa': 'او...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>495789 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3ac04d3-315e-4a4e-b3ac-5594381589ed')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b3ac04d3-315e-4a4e-b3ac-5594381589ed button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b3ac04d3-315e-4a4e-b3ac-5594381589ed');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dataset['train'][0]['translation']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4b771f2-1fd4-4ff9-bf33-4094dc81e60d","executionInfo":{"status":"ok","timestamp":1658389079756,"user_tz":-270,"elapsed":458,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"SYtkP--Vv7Y7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'en': 'so , dish . i just wanna make sure my .',\n"," 'fa': 'پس میخام مطمئن بشم که. '}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import datasets\n","import random\n","from IPython.display import display, HTML\n","def show_random_elements(dataset, num_examples=5):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, datasets.ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","    display(HTML(df.to_html()))\n","show_random_elements(dataset[\"train\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"a8a79b9b-da44-40ac-f09e-f4ab12622c4c","executionInfo":{"status":"ok","timestamp":1658389083096,"user_tz":-270,"elapsed":5,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"Fk2vnA7qv7Y8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'en': 'you may notice that it hasthe vangor family crest stamped on it. .', 'fa': 'میبینی که پشتش علامت تاج خونواده ونگور مهر شده. '}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'en': 'dry pleurisy .', 'fa': 'ذات الجنب خشک. '}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'en': 'im gonna find you .', 'fa': 'من پیدات میکنم. '}</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'en': 'i know you young people are always .', 'fa': 'میدونم که شما جوونها. '}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'en': 'ill help you this one time .', 'fa': 'این یک دفعه را کمک تون میکنم. '}</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["fake_preds = [\"hello there\", \"سلام\"]\n","fake_labels = [[\"hello there\"], [\"سلام\"]]\n","metric.compute(predictions=fake_preds, references=fake_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b15f10b9-60fb-4732-bddd-feac873ae12b","executionInfo":{"status":"ok","timestamp":1658389116511,"user_tz":-270,"elapsed":403,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"d7pLN4JFv7Y8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bp': 1.0,\n"," 'counts': [3, 1, 0, 0],\n"," 'precisions': [100.0, 100.0, 0.0, 0.0],\n"," 'ref_len': 3,\n"," 'score': 0.0,\n"," 'sys_len': 3,\n"," 'totals': [3, 1, 0, 0]}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n","\n","model_size = \"small\"\n","model_name = f\"persiannlp/mt5-{model_size}-parsinlu-translation_en_fa\"\n","tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","\n","\n","def run_model(input_string, **generator_args):\n","    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n","    res = model.generate(input_ids, **generator_args)\n","    output = tokenizer.batch_decode(res, skip_special_tokens=True)\n","    print(output)\n","    return output\n","\n","\n","# run_model(\"Praise be to Allah, the Cherisher and Sustainer of the worlds;\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["9489bad5e89e487ebcedce36fcce8361","ce2cbc3cdf494bb680c5cc07ca7d9df8","1d7585d67ae4460282ae3bfd88987c54","c20669620604443cb05ceac82bcdb150","b1515bfaf2b44f73a5c00ae1b1663de3","fec5019fa09d47d48fc5fd9e47f25288","de2ad74716f941b3b4ed246802910498","4d399f44eeb044b596d21adab5ffc5a8","6d3ac8d3930d4eceaee8cff00170b11e","9215eec9195843458c728f58f583bc09","5f974155d9bc48ff892a050223c8837c","4d0e04996f004e1ebab91f93a7851254","074735761a664cc9bc467f5966d51e73","90f862f28406428480cbf3e955ae6ca3","7ebbe4c7e288485882168d3c5d25122f","989dbef013664f0b8d7788ee136497e7","863d777450574d658e87c7f324da4cc2","06ed41d922944d12aa5fd28581af00e0","ac7f223fd3aa4b57958844115f1954fc","4954d09b303a413986b18d8355eeb995","c6af73b110d44947868854777903552f","23960d9bd5c54866af9da92541ba4125","d622b771e63747e696e7165d5a79a40f","767b5f26687a4bcc89f57184e1a8f4b8","3a1e7c9195744efbac1417646e10def5","1b9c89fccb744d21882ff695322fcf7a","3b359e7c722d4e4bb387e29db4e1d5fc","6193ec2a5d0f4bf4b4ab5aea100af529","69b3a7fb60b6486f97c77c8deb7b5a81","8ab6f0504dfc44c6bda34674b64c8624","16d127227d16498a836a7f21d58ac2aa","41353406433448cd9b3972723e84273c","3c67a44376144b3b85f337f4be1e6816","0cd50e6c6417484bb58fcf99ce94b704","7c5a5c50e21646a9957f47d1b568a0b6","36e9f3bbbbcb479285327e2417aacb07","00bf1a64f72f49698706df892fe4f4e8","9bcab124b21d41d98996ce034cdc101b","932f6c1e5a1143289b222ff68b4e3a3c","92c93fc1b0384999a12a47532bde92d8","4a407e6da5d14675a1b919c55076292a","ef20591c668b401386c42499a832fe22","e4079390419846aa902eb88a7ce3ea70","03426a1993fa42b6a37afb8328d6dc0f","e9b1b78228114b71853b15f3f56a6890","18b02b6d210f4dc1905e43cc66acf8d5","94300c3c49044b659b7164254e413d9d","95f93942fdc74a6686a4a277bb9f465a","e3e15e5cb9204525807b9842340951d1","66b2dc208465441ea336abdff8be4273","8b6ea384ad354632be3424a8586768a0","9b2541f0f352424cae69085deae9f2b0","19991840679a4269bd6e792f3c876dc5","c67c1032956f4bd7aef8a79b7e82d747","7795db3ba1124cd9a0ca92b779adbf6f"]},"outputId":"64f4cf3c-0043-447d-f7fa-de2747d6cb05","executionInfo":{"status":"ok","timestamp":1658389239544,"user_tz":-270,"elapsed":110970,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"2Mim1mB9v7Y8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/4.11M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9489bad5e89e487ebcedce36fcce8361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0e04996f004e1ebab91f93a7851254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d622b771e63747e696e7165d5a79a40f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/609 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd50e6c6417484bb58fcf99ce94b704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b1b78228114b71853b15f3f56a6890"}},"metadata":{}}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"672005d1-4ec4-4201-ef3d-c1abfe8b8dba","executionInfo":{"status":"ok","timestamp":1658389240099,"user_tz":-270,"elapsed":562,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"Ii58DkYUv7Y8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jul 21 07:40:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["%reset -f"],"metadata":{"id":"txNx3i61v7Y8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ea8b9b0-9de0-4a58-95a8-6365e55f83b6","executionInfo":{"status":"ok","timestamp":1658389246004,"user_tz":-270,"elapsed":413,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"TkWJYuaqv7Y9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[30273, 261, 714, 1371, 259, 98923, 309, 1], [1494, 339, 259, 7845, 259, 98923, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["with tokenizer.as_target_tokenizer():\n","    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5dc5edb2-a4b4-47da-e343-398c954b75ae","executionInfo":{"status":"ok","timestamp":1658389247638,"user_tz":-270,"elapsed":2,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"wzZ4-POmv7Y9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[30273, 261, 714, 1371, 259, 98923, 309, 1], [1494, 339, 259, 7845, 259, 98923, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}]},{"cell_type":"code","source":["prefix = \"\"\n","max_input_length = 128\n","max_target_length = 128\n","source_lang = \"fa\"\n","target_lang = \"en\"\n","def preprocess_function(examples):\n","    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"ZKx28tW5v7Y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_function(dataset['train'][:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f1878dd-1d5d-40ea-c9d3-7fa40652300f","executionInfo":{"status":"ok","timestamp":1658389261113,"user_tz":-270,"elapsed":3,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"OiyVUktMv7Y9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[6423, 822, 41950, 8764, 633, 26081, 21470, 633, 934, 260, 1], [259, 1699, 259, 112382, 4283, 259, 53522, 554, 11632, 2791, 509, 4299, 548, 43017, 3237, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[510, 259, 261, 90564, 259, 260, 259, 266, 1627, 259, 82711, 2149, 7779, 1037, 259, 260, 1], [776, 288, 65143, 461, 2780, 680, 83478, 259, 260, 1]]}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["tokenized_datasets = dataset.map(preprocess_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150,"referenced_widgets":["204a5878dbc9406ebd33e6e9d9c5ed11","ea0dddff552a4431a1df458abbdaeccb","3a0164174fc44659b1ed90ce25503adc","31c113584fd0441eaa0bf9839aa6e05b","c6237de04b104706a16f94c9d511ad61","0316d8d11c814d71b50b65f2a2555335","72d4478f14324301b285b6c9f071fa09","57689297e57d4ea0b741d9862bb5308b","9d94a667a27b44b987c1bf02bb1546d8","3206eb46a2a9423c914fc044e8b93ca1","0d8d68acfdb2484898ee3f4efb77d1c6","7ac941e629f74584b35687241e50ef06","5a30cf5490bc4dfeab4887dbdcac1619","84fb2a5cb6924980b091cc09dc4031ba","240c7a21265e481d868f87f8d4f3aaa9","55e67f41cc67443880a0b99fea3ecc29","9bd270290d5347d1bf397cb6c86451b7","e1a7720318a1479ea246547a2f0a9030","f3644b2fd7834f1a82ab504cc3a05403","c07e029c76c9466681c02f2db047a40e","7c0de26dfb654d2f914df7e7440d67f5","204ef9cc95ba41f79d7b3e0533c4735e","0000732732af4cf2a3e37e1590bcc120","c058ee0cb47841edab4ea23afd4762cf","c314debcb57348678a10b020285c792e","186f9058da3943b3a98179b5525394f2","3280a88f33df436f842f6da5b4e047c6","839e8ccc4979408d868bacec6748540a","39286982bbaa43ddb26f30bd07144a2b","e120dc03c5d64a3c906d37fe23b2baae","85d568a74a11423cb9ab5c65d6560ce4","3057d835440b4502bfc8b7a7924563d4","7e67702b34d74ce89c32fab9f91d43eb"]},"outputId":"8fb734b2-ddfa-479b-e2a9-27bc2c2f1a91","executionInfo":{"status":"ok","timestamp":1658389374220,"user_tz":-270,"elapsed":109478,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"X0m4MOsmv7Y9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Parameter 'function'=<function preprocess_function at 0x7fcf077d94d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/496 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204a5878dbc9406ebd33e6e9d9c5ed11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/62 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ac941e629f74584b35687241e50ef06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/56 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0000732732af4cf2a3e37e1590bcc120"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"],"metadata":{"id":"Q2tzKZR8v7Y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299,"referenced_widgets":["1d919a916fc34732b098e853fb33c4eb","1957605028154c6f973e4ce9d725f1af","d92e0b07769544a398b31a9959720693","bfa61a85ce1d4c188b831b3a997ed170","54ccb2c6a3af46ad8349c38498c63c23","bd6e6b5287e34c738d2e5482c40440cd","54e4642c940e4de08aab38c6cff4f991","98539bb31da24a4b9ce3157c80e3e4c2","f8ef7ecb5beb43f8be17ae5eafb2aa0a","aea3d318293b45b8afd6a483355baab6","e44f9bfe568c430d937846bbb3c203fb","e61d7647f45547d2adb21a9cd6e67fb7","5897f1278d6a4defa10ab624cf9c00b8","03f23364a57c402482126e469eb91d1b"]},"id":"Ti4V8QixrloQ","outputId":"92e08e01-1b60-49d1-e0e2-ae9e8ca5898d","executionInfo":{"status":"ok","timestamp":1658389375934,"user_tz":-270,"elapsed":9,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPsbjGGIsM2d","outputId":"31fbb11b-362e-49bb-d592-1a15ec9b12bf","executionInfo":{"status":"ok","timestamp":1658389417452,"user_tz":-270,"elapsed":3772,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["batch_size = 16\n","args = Seq2SeqTrainingArguments(\n","    \"finetuned_translation_fa_en\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    num_train_epochs=1,\n","    predict_with_generate=True,\n","    push_to_hub=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"894fde7b-148d-45a8-ceab-aafe5daeafe0","executionInfo":{"status":"ok","timestamp":1658389541051,"user_tz":-270,"elapsed":3,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"AhVna6kvv7Y-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"cTakuQzxv7Y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","    return preds, labels\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"],"metadata":{"id":"2dsCmdlEv7Y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d47c0d39-9c70-497a-f7c4-daa7dc7b0fee","executionInfo":{"status":"ok","timestamp":1658389573126,"user_tz":-270,"elapsed":4014,"user":{"displayName":"Mohammad Rashidkhan","userId":"06705842747500311974"}},"id":"7YS5siG8v7Y-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/finetuned_translation_fa_en is already a clone of https://huggingface.co/mehdidn/finetuned_translation_fa_en. Make sure you pull the latest changes with `repo.git_pull()`.\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"48500eba-65ce-410b-8cac-548933cbcf72","id":"WFkeL6ZFv7Y-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation. If translation are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 495789\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 30987\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2708' max='30987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2708/30987 07:19 < 1:16:34, 6.15 it/s, Epoch 0.09/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["trainer.push_to_hub(\"End of training\")"],"metadata":{"id":"t4LMRu1MYfBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n","src_text = ['hello my brother']\n","model_name = 'finetuned_translation_fa_en'\n","tokenizer = MT5Tokenizer.from_pretrained(model_name)\n","model = MT5ForConditionalGeneration.from_pretrained(model_name)\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"],"metadata":{"id":"ndxOuEouv7Y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","for dirname, _, filenames in os.walk('opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"metadata":{"id":"j52aTQaxv7Y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/u/0/uc?id=1MwBr0AeZkLysDGPHn35kl-ATmfMV_WSp&export=download"],"metadata":{"id":"k88-PJLULvAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run_model(\"Praise be to Allah, the Cherisher and Sustainer of the worlds;\")"],"metadata":{"id":"5tXRshiiwRVI"},"execution_count":null,"outputs":[]}]}